<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /></head>
<body>
<p>
Carrot<sup>2</sup> is an Open Source Search Results Clustering Engine, which can
automatically organize small collections of documents, for example search results,
into thematic categories, <a href="#overview_description">see below for more</a>.
</p>

<h1>Downloads &amp; more information</h1>
<p>
<a href="http://project.carrot2.org/download-java-api.html" class="download-small">Java API JAR, JavaDocs and example code</a><br />
<a href="http://project.carrot2.org/download.html" class="download-small">Other Carrot2 applications</a><br />
<a href="http://download.carrot2.org/head/manual/index.html" class="view-small">User and Developer Manual</a><br />
<a href="http://download.carrot2.org/head/manual/index.html#section.integration.adding-to-maven-project" class="view-small">Instructions for Maven2 users</a><br />
<a href="http://project.carrot2.org" class="view-small">Carrot2 project website</a><br />
<a href="http://search.carrot2.org" class="view-small">Carrot2 on-line demo</a>
</p>

<h1>Java API usage examples</h1>
<p>
  You can use Carrot<sup>2</sup> Java API to fetch documents from various sources (public search engines, Lucene, Solr), perform clustering, serialize the results to JSON or XML and many more. Below is some example code for the most common use cases. Please see the <tt>examples/</tt> directory in the <a href="http://project.carrot2.org/download-java-api.html">Java API distribution archive</a> for more examples.
</p>

<a name="clustering-from-document-sources"></a>
<h2>Clustering documents from document sources</h2>
<p>
The most common way to use Carrot<sup>2</sup> Java API is to fetch a number of
documents from some {@link org.carrot2.core.IDocumentSource} and cluster them
using some {@link org.carrot2.core.IClusteringAlgorithm}. The general pattern
for this kind of invocation is to put all input data required for processing
(query and required number of results in this case) into a map and pass that
map to an {@link org.carrot2.core.IController} that will perform all the processing.
The code shown below retrieves 100 search results from {@link org.carrot2.source.microsoft.MicrosoftLiveDocumentSource}
and clusters them using the {@link org.carrot2.clustering.lingo.LingoClusteringAlgorithm}.
</p>

<pre class="brush: java">
        /* A controller to manage the processing pipeline. */
        IController controller = new SimpleController();

        /* Input data for clustering, the query and number of results in this case. */
        Map&lt;String, Object> attributes = new HashMap&lt;String, Object>();
        attributes.put(AttributeNames.QUERY, "data mining");
        attributes.put(AttributeNames.RESULTS, 100);

        /* Perform processing */
        ProcessingResult result = controller.process(attributes,
            MicrosoftLiveDocumentSource.class, LingoClusteringAlgorithm.class);
        
        /* Documents fetched from the document source, clusters created by Carrot2. */
        List&lt;Document> documents = result.getDocuments();
        List&lt;Cluster> clusters = result.getClusters();
</pre>
<a class="source-link" href="http://fisheye3.atlassian.com/browse/carrot2/trunk/applications/carrot2-examples/src/org/carrot2/examples/clustering/ClusteringDataFromDocumentSources.java?r=trunk">View full source code</a>

<a name="clustering-documents"></a>
<h2>Clustering arbitrary documents</h2>

<p>
You can also directly pass a list of {@link org.carrot2.core.Document} instances for clustering:
</p>

<pre class="brush: java">
        /* A few example documents, normally you would need at least 20 for reasonable clusters. */
        final String [][] data = new String [] []
        {
            {
                "http://en.wikipedia.org/wiki/Data_mining",
                "Data mining - Wikipedia, the free encyclopedia",
                "Article about knowledge-discovery in databases (KDD), the practice of automatically searching large stores of data for patterns."
            },

            {
                "http://www.ccsu.edu/datamining/resources.html",
                "CCSU - Data Mining",
                "A collection of Data Mining links edited by the Central Connecticut State University ... Graduate Certificate Program. Data Mining Resources. Resources. Groups ..."
            },

            {
                "http://www.kdnuggets.com/",
                "KDnuggets: Data Mining, Web Mining, and Knowledge Discovery",
                "Newsletter on the data mining and knowledge industries, offering information on data mining, knowledge discovery, text mining, and web mining software, courses, jobs, publications, and meetings."
            },

            {
                "http://en.wikipedia.org/wiki/Data-mining",
                "Data mining - Wikipedia, the free encyclopedia",
                "Data mining is considered a subfield within the Computer Science field of knowledge discovery. ... claim to perform \"data mining\" by automating the creation ..."
            },

            {
                "http://www.anderson.ucla.edu/faculty/jason.frand/teacher/technologies/palace/datamining.htm",
                "Data Mining: What is Data Mining?",
                "Outlines what knowledge discovery, the process of analyzing data from different perspectives and summarizing it into useful information, can do and how it works."
            },
        };
        ArrayList&lt;Document> documents = new ArrayList&lt;Document>();
        for (String [] row : data)
        {
            documents.add(new Document(row[1], row[2], row[0]));
        }

        /* A controller to manage the processing pipeline. */
        SimpleController controller = new SimpleController();

        /* Input data for clustering, list of Documents in this case. */
        Map&lt;String, Object> attributes = new HashMap&lt;String, Object>();
        attributes.put(AttributeNames.DOCUMENTS, documents);

        /* Perform clustering */
        ProcessingResult result = controller.process(attributes,
            LingoClusteringAlgorithm.class);
  
        /* Clusters created by Carrot2. */
        List&lt;Cluster> clusters = result.getClusters();
</pre>
<a class="source-link" href="http://fisheye3.atlassian.com/browse/carrot2/trunk/applications/carrot2-examples/src/org/carrot2/examples/clustering/ClusteringDocumentList.java?r=trunk">View full source code</a>

<a name="caching-controller"></a>
<h2>Using {@link org.carrot2.core.CachingController}</h2>

<p>
  The examples above used an instance of {@link org.carrot2.core.SimpleController} 
  to manage the clustering process. While {@link org.carrot2.core.SimpleController}
  is enough for one-shot requests, for long-running applications, such as web 
  applications, it's better to use the {@link org.carrot2.core.CachingController}, 
  which is thread-safe, supports processing component pooling and results caching:
</p>

<pre class="brush: java">
        /*
         * Create the caching controller. You need only one caching controller instance
         * per application life cycle. This controller instance will cache the results
         * fetched from any document source and also clusters generated by the Lingo
         * algorithm.
         */
        CachingController controller = new CachingController(IDocumentSource.class,
            LingoClusteringAlgorithm.class);

        /*
         * Before using the caching controller, you must initialize it. On initialization,
         * we can set some default values of input data (called attributes). In this
         * example, we'll set the default results number to 50.
         */
        Map&lt;String, Object> globalAttributes = new HashMap&lt;String, Object>();
        globalAttributes.put(AttributeNames.RESULTS, 50);
        controller.init(globalAttributes);

        /*
         * The controller is now ready to perform queries. To show that the documents from
         * the document input are cached, we will perform the same query twice and measure
         * the time for each query.
         */
        Map&lt;String, Object> attributes;
        ProcessingResult result;
        long start, duration;
        
        start = System.currentTimeMillis();
        attributes = new HashMap&lt;String, Object>();
        attributes.put(AttributeNames.QUERY, "data mining");
        result = controller.process(attributes,
            MicrosoftLiveDocumentSource.class, LingoClusteringAlgorithm.class);
        duration = System.currentTimeMillis() - start;
        System.out.println(duration + " ms (empty cache)");
        
        start = System.currentTimeMillis();
        attributes = new HashMap&lt;String, Object>();
        attributes.put(AttributeNames.QUERY, "data mining");
        result = controller.process(attributes,
            MicrosoftLiveDocumentSource.class, LingoClusteringAlgorithm.class);
        duration = System.currentTimeMillis() - start;
        System.out.println(duration + " ms (documents and clusters from cache)");
</pre>
<a class="source-link" href="http://fisheye3.atlassian.com/browse/carrot2/trunk/applications/carrot2-examples/src/org/carrot2/examples/clustering/UsingCachingController.java?r=trunk">View full source code</a>

<a name="non-english"></a>
<h2>Clustering non-English content</h2>

<p>
  By default Carrot2 algorithms assume the content is in English and use the
  tokenizer, stemmer and stop words appropriate for that language. There are
  two ways of performing non-English clustering in Carrot2:
  <ol>
    <li>Set the {@link org.carrot2.core.attribute.AttributeNames#ACTIVE_LANGUAGE} attribute to the appropriate value
    from {@link org.carrot2.text.linguistic.LanguageCode}, which will make the clustering algorithm use the tokenizer,
    stemmer and lexical resources dedicated to that language</li>
    <li>When using a document source that can return content in different languages,
    {@link org.carrot2.core.attribute.AttributeNames#ACTIVE_LANGUAGE} will be determined based on the source-specific
    language attribute. Currently, three document sources support language choice:
    <ol>
      <li>{@link org.carrot2.source.microsoft.MicrosoftLiveDocumentSource} through the
      {@link org.carrot2.source.microsoft.MicrosoftLiveDocumentSource#culture} attribute</li>
      <li>{@link org.carrot2.source.boss.BossDocumentSource} through the {@link org.carrot2.source.boss.BossSearchService#languageAndRegion}
      attribute</li>
      <li>{@link org.carrot2.source.etools.EToolsDocumentSource} through the {@link org.carrot2.source.etools.EToolsDocumentSource#language}
      attribute</li>
    </ol></li>
  </ol>
  The following example demonstrates both approaches:
</p>

<pre class="brush: java">
        /*
         * We use a CachingController here to reuse instances of Carrot2 processing
         * components. This is especially important when the components are expensive to
         * create, which is the case with ChineseAnalyzer.
         */
        CachingController controller = new CachingController(IDocumentSource.class);

        /*
         * No special initialization-time attributes in this example.
         */
        Map&lt;String, Object> initAttributes = new HashMap&lt;String, Object>();
        controller.init(initAttributes);

        /*
         * In the first call, we will fetch Chinese search results from MSN Live, but as
         * we don't explicitly set the document source's language to Chinese, we'll need
         * to provide the active language attribute.
         */
        Map&lt;String, Object> attributes = new HashMap&lt;String, Object>();
        attributes.put(AttributeNames.QUERY, "??"); // clustering?
        attributes.put(AttributeNames.RESULTS, 100);
        attributes.put(AttributeNames.ACTIVE_LANGUAGE, LanguageCode.CHINESE_SIMPLIFIED);

        /*
         * Perform clustering and display results.
         */
        ProcessingResult chineseResult = controller.process(attributes,
            MicrosoftLiveDocumentSource.class, LingoClusteringAlgorithm.class);
        List&lt;Cluster> chineseClusters = chineseResult.getClusters();

        /*
         * In the second call, we will fetch German search results from eTools, and
         * explicitly instruct the document source to return results in German. In this
         * case, we don't need to set the active language attribute because the document
         * source will set it for us accordingly.
         */
        attributes.clear();
        attributes.put(AttributeNames.QUERY, "bundestag");
        attributes.put(AttributeNames.RESULTS, 100);
        attributes.put("EToolsDocumentSource.language", EToolsDocumentSource.Language.GERMAN);
        ProcessingResult germanResult = controller.process(attributes,
            EToolsDocumentSource.class, LingoClusteringAlgorithm.class);
        List&lt;Cluster> germanClusters = germanResult.getClusters();
</pre>
<a class="source-link" href="http://fisheye3.atlassian.com/browse/carrot2/trunk/applications/carrot2-examples/src/org/carrot2/examples/clustering/ClusteringNonEnglishContent.java?r=trunk">View full source code</a>
<p>
&nbsp;
</p>

<link type="text/css" rel="stylesheet" href="{@docRoot}/sh/shCore.css"/>
<link type="text/css" rel="stylesheet" href="{@docRoot}/sh/shThemeDefault.css"/>
<script type="text/javascript" src="{@docRoot}/sh/shCore.js"></script>
<script type="text/javascript" src="{@docRoot}/sh/shBrushJava.js"></script>
<script type="text/javascript">
  SyntaxHighlighter.defaults.light = false;
  SyntaxHighlighter.defaults.gutter = false;
  SyntaxHighlighter.all();
</script>

</body>
</html>
