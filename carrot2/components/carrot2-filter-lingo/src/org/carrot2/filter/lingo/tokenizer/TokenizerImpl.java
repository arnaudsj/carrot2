
/*
 * Carrot2 project.
 *
 * Copyright (C) 2002-2006, Dawid Weiss, Stanisław Osiński.
 * Portions (C) Contributors listed in "carrot2.CONTRIBUTORS" file.
 * All rights reserved.
 *
 * Refer to the full license file "carrot2.LICENSE"
 * in the root folder of the repository checkout or at:
 * http://www.carrot2.org/carrot2.LICENSE
 */

package org.carrot2.filter.lingo.tokenizer;

/**
 * Implementation of abstract Tokenizer class generated by JavaCC parser
 * generator.
 */
class TokenizerImpl implements TokenizerImplConstants {
    /** DOCUMENT ME! */
    public TokenizerImplTokenManager token_source;

    /** DOCUMENT ME! */
    SimpleCharStream jj_input_stream;

    /** DOCUMENT ME! */
    public Token token;

    /** DOCUMENT ME! */
    public Token jj_nt;

    /** DOCUMENT ME! */
    private int jj_ntk;

    /** DOCUMENT ME! */
    private int jj_gen;

    /** DOCUMENT ME! */
    private final int[] jj_la1 = new int[0];

    /** DOCUMENT ME! */
    private final int[] jj_la1_0 = {  };

    /**
     * Creates a new TokenizerImpl object.
     *
     * @param stream DOCUMENT ME!
     */
    public TokenizerImpl(java.io.InputStream stream) {
        jj_input_stream = new SimpleCharStream(stream, 1, 1);
        token_source = new TokenizerImplTokenManager(jj_input_stream);
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++) {
            jj_la1[i] = -1;
        }
    }

    /**
     * DOCUMENT ME!
     *
     * @param stream DOCUMENT ME!
     */
    public void ReInit(java.io.InputStream stream) {
        jj_input_stream.ReInit(stream, 1, 1);
        token_source.ReInit(jj_input_stream);
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++) {
            jj_la1[i] = -1;
        }
    }

    /**
     * Creates a new TokenizerImpl object.
     *
     * @param stream DOCUMENT ME!
     */
    public TokenizerImpl(java.io.Reader stream) {
        jj_input_stream = new SimpleCharStream(stream, 1, 1);
        token_source = new TokenizerImplTokenManager(jj_input_stream);
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++) {
            jj_la1[i] = -1;
        }
    }

    /**
     * DOCUMENT ME!
     *
     * @param stream DOCUMENT ME!
     */
    public void ReInit(java.io.Reader stream) {
        jj_input_stream.ReInit(stream, 1, 1);
        token_source.ReInit(jj_input_stream);
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++) {
            jj_la1[i] = -1;
        }
    }

    /**
     * Creates a new TokenizerImpl object.
     *
     * @param tm DOCUMENT ME!
     */
    public TokenizerImpl(TokenizerImplTokenManager tm) {
        token_source = tm;
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++) {
            jj_la1[i] = -1;
        }
    }

    /**
     * DOCUMENT ME!
     *
     * @param tm DOCUMENT ME!
     */
    public void ReInit(TokenizerImplTokenManager tm) {
        token_source = tm;
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++) {
            jj_la1[i] = -1;
        }
    }

    /**
     * DOCUMENT ME!
     *
     * @param kind DOCUMENT ME!
     *
     * @return DOCUMENT ME!
     *
     * @throws ParseException DOCUMENT ME!
     */
    private final Token jj_consume_token(int kind) throws ParseException {
        Token oldToken;

        if ((oldToken = token).next != null) {
            token = token.next;
        } else {
            token = token.next = token_source.getNextToken();
        }

        jj_ntk = -1;

        if (token.kind == kind) {
            jj_gen++;

            return token;
        }

        token = oldToken;
        jj_kind = kind;
        throw generateParseException();
    }

    /**
     * DOCUMENT ME!
     *
     * @return DOCUMENT ME!
     */
    public final Token getNextToken() {
        if (token.next != null) {
            token = token.next;
        } else {
            token = token.next = token_source.getNextToken();
        }

        jj_ntk = -1;
        jj_gen++;

        return token;
    }

    /**
     * DOCUMENT ME!
     *
     * @param index DOCUMENT ME!
     *
     * @return DOCUMENT ME!
     */
    public final Token getToken(int index) {
        Token t = token;

        for (int i = 0; i < index; i++) {
            if (t.next != null) {
                t = t.next;
            } else {
                t = t.next = token_source.getNextToken();
            }
        }

        return t;
    }

    /**
     * DOCUMENT ME!
     *
     * @return DOCUMENT ME!
     */
    private final int jj_ntk() {
        if ((jj_nt = token.next) == null) {
            return (jj_ntk = (token.next = token_source.getNextToken()).kind);
        } else {
            return (jj_ntk = jj_nt.kind);
        }
    }

    /** DOCUMENT ME! */
    private java.util.Vector jj_expentries = new java.util.Vector();

    /** DOCUMENT ME! */
    private int[] jj_expentry;

    /** DOCUMENT ME! */
    private int jj_kind = -1;

    /**
     * DOCUMENT ME!
     *
     * @return DOCUMENT ME!
     */
    public final ParseException generateParseException() {
        jj_expentries.removeAllElements();

        boolean[] la1tokens = new boolean[19];

        for (int i = 0; i < 19; i++) {
            la1tokens[i] = false;
        }

        if (jj_kind >= 0) {
            la1tokens[jj_kind] = true;
            jj_kind = -1;
        }

        for (int i = 0; i < 0; i++) {
            if (jj_la1[i] == jj_gen) {
                for (int j = 0; j < 32; j++) {
                    if ((jj_la1_0[i] & (1 << j)) != 0) {
                        la1tokens[j] = true;
                    }
                }
            }
        }

        for (int i = 0; i < 19; i++) {
            if (la1tokens[i]) {
                jj_expentry = new int[1];
                jj_expentry[0] = i;
                jj_expentries.addElement(jj_expentry);
            }
        }

        int[][] exptokseq = new int[jj_expentries.size()][];

        for (int i = 0; i < jj_expentries.size(); i++) {
            exptokseq[i] = (int[]) jj_expentries.elementAt(i);
        }

        return new ParseException(token, exptokseq, tokenImage);
    }

    /**
     * DOCUMENT ME!
     */
    public final void enable_tracing() {
    }

    /**
     * DOCUMENT ME!
     */
    public final void disable_tracing() {
    }
}
